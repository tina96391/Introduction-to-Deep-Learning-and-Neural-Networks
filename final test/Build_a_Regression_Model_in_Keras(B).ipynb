{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build a Regression Model in Keras(B).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBT_2iM0_jmj"
      },
      "source": [
        "# Start import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaxdftqR-hDp",
        "outputId": "2ee1cc11-e9e8-4104-b89c-2b93938dbb13"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "concrete_data = pd.read_csv('concrete_data.csv')\r\n",
        "concrete_data.head()\r\n",
        "concrete_data.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cement                0\n",
              "Blast Furnace Slag    0\n",
              "Fly Ash               0\n",
              "Water                 0\n",
              "Superplasticizer      0\n",
              "Coarse Aggregate      0\n",
              "Fine Aggregate        0\n",
              "Age                   0\n",
              "Strength              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo13on-3_uA-"
      },
      "source": [
        "# Build a baseline model\r\n",
        "Use the Keras library to build a neural network with the following:\r\n",
        "\r\n",
        "- One hidden layer of **10** nodes, and a **ReLU** activation function\r\n",
        "\r\n",
        "- Use the **adam** optimizer and the **mean squared erro**r  as the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jY5GCFw_zyH"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO6aAZ5kAEBI"
      },
      "source": [
        "def regression_model():\r\n",
        "    # create model with 10 nodes and a relu function\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(10, activation='relu', input_shape=(n_pred_cols ,)))\r\n",
        "    model.add(Dense(1))\r\n",
        "    \r\n",
        "    # compile model\r\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\r\n",
        "    return model\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZ82NwOAfJv"
      },
      "source": [
        "1. Randomly split the data into a training and test sets by holding **30%** of the data for testing. You can use the **train_test_splithelper function from Scikit-learn**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS9tjGpEAa3l"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md1LLHK7HN9Y"
      },
      "source": [
        "# normalized version of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQRLab5RA2Bx"
      },
      "source": [
        "# we need to use Strength column as our target to predict\r\n",
        "concrete_data_columns = concrete_data.columns\r\n",
        "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] \r\n",
        "target = concrete_data['Strength'] \r\n",
        "\r\n",
        "predictors_norm = (predictors - predictors.mean()) / predictors.std()\r\n",
        "predictors_norm.head()\r\n",
        "\r\n",
        "n_pred_cols = predictors.shape[1] # number of predictors\r\n",
        "n_pred_cols\r\n",
        "\r\n",
        "# split predictors data into training data and testing data (predictors is the column without Strength)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=40)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb7TdszuB-g3"
      },
      "source": [
        "2. Train the model on the training data using **50 epochs**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4XIuoNSBUNo",
        "outputId": "cbf81d33-6ca0-4048-d90f-15f2a0d22785"
      },
      "source": [
        "model = regression_model()\r\n",
        "epochs = 50\r\n",
        "model.fit(X_train, y_train, epochs=epochs, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 1s 1ms/step - loss: 35610.8832\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 14744.4845\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 6622.3261\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 4565.9557\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 4362.8436\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 3945.4916\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3992.1134\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 3622.2704\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 3340.1454\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3313.3235\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 2814.1794\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 3125.4415\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 2832.5432\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 2338.8604\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 2458.7122\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2291.7378\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 2137.6863\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1992.2313\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1603.9130\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1491.1838\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1435.5300\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1314.1400\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1271.6137\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1083.3070\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 878.5307\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 841.1449\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 684.1704\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 665.2829\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 610.3960\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 571.1115\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 559.8843\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 525.1752\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 476.7159\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 452.9183\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 427.4605\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 435.6112\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 398.2808\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 372.6775\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 370.4418\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 416.0451\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 370.0936\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 372.7223\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 355.3298\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 347.9620\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 362.7993\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 332.3624\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 360.0854\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 364.9772\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 319.0197\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 351.9009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6d57e842e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF0VY8ggDn36",
        "outputId": "e10cfe91-1bc2-4b80-b837-1e64a1badf17"
      },
      "source": [
        "loss = model.evaluate(X_test, y_test)\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "loss"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 317.5180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "317.5179748535156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wB_Q3J4Defr"
      },
      "source": [
        "3. Evaluate the model on the test data and compute the **mean squared error** between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6KBGICNDce2",
        "outputId": "715a52fe-4a15-4c4a-b3d5-af9d49a8fdcf"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "mean_square_error = mean_squared_error(y_test, y_pred)\r\n",
        "mean = np.mean(mean_square_error)\r\n",
        "standard_deviation = np.std(mean_square_error)\r\n",
        "print(mean, standard_deviation)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "317.517985564185 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D82Uc3R1EBxb"
      },
      "source": [
        "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdk9h4mXEFQ4",
        "outputId": "20e3adf0-5dcf-43a2-ae3a-b9957315dd3b"
      },
      "source": [
        "repeat = 50\r\n",
        "epochs = 50\r\n",
        "mean_squared_errors = []\r\n",
        "for i in range(0, repeat):\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=i)\r\n",
        "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\r\n",
        "    MSE = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "    print(\"mean_squared_errors \"+str(i+1)+\": \"+str(MSE))\r\n",
        "    y_pred = model.predict(X_test)\r\n",
        "    mean_square_error = mean_squared_error(y_test, y_pred)\r\n",
        "    mean_squared_errors.append(mean_square_error)\r\n",
        "\r\n",
        "mean_squared_errors = np.array(mean_squared_errors)\r\n",
        "mean = np.mean(mean_squared_errors)\r\n",
        "standard_deviation = np.std(mean_squared_errors)\r\n",
        "\r\n",
        "print(\"Mean: \"+str(mean))\r\n",
        "print(\"Standard Deviation: \"+str(standard_deviation))\r\n",
        "print('\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_squared_errors 1: 236.31973266601562\n",
            "mean_squared_errors 2: 207.0643768310547\n",
            "mean_squared_errors 3: 191.47076416015625\n",
            "mean_squared_errors 4: 178.256591796875\n",
            "mean_squared_errors 5: 120.83695983886719\n",
            "mean_squared_errors 6: 77.94718170166016\n",
            "mean_squared_errors 7: 79.671875\n",
            "mean_squared_errors 8: 51.968963623046875\n",
            "mean_squared_errors 9: 56.916927337646484\n",
            "mean_squared_errors 10: 49.25264358520508\n",
            "mean_squared_errors 11: 46.78462219238281\n",
            "mean_squared_errors 12: 45.665103912353516\n",
            "mean_squared_errors 13: 53.308006286621094\n",
            "mean_squared_errors 14: 51.43015670776367\n",
            "mean_squared_errors 15: 48.3785285949707\n",
            "mean_squared_errors 16: 42.6342887878418\n",
            "mean_squared_errors 17: 46.661102294921875\n",
            "mean_squared_errors 18: 51.99457931518555\n",
            "mean_squared_errors 19: 43.18507766723633\n",
            "mean_squared_errors 20: 46.64744186401367\n",
            "mean_squared_errors 21: 43.926368713378906\n",
            "mean_squared_errors 22: 45.14995193481445\n",
            "mean_squared_errors 23: 44.85939407348633\n",
            "mean_squared_errors 24: 43.992835998535156\n",
            "mean_squared_errors 25: 45.60639953613281\n",
            "mean_squared_errors 26: 47.507720947265625\n",
            "mean_squared_errors 27: 48.24063491821289\n",
            "mean_squared_errors 28: 42.94823455810547\n",
            "mean_squared_errors 29: 49.72304916381836\n",
            "mean_squared_errors 30: 46.311256408691406\n",
            "mean_squared_errors 31: 47.72334671020508\n",
            "mean_squared_errors 32: 40.91958999633789\n",
            "mean_squared_errors 33: 45.65555953979492\n",
            "mean_squared_errors 34: 47.225624084472656\n",
            "mean_squared_errors 35: 49.656185150146484\n",
            "mean_squared_errors 36: 48.4372673034668\n",
            "mean_squared_errors 37: 47.9677848815918\n",
            "mean_squared_errors 38: 48.7542839050293\n",
            "mean_squared_errors 39: 45.59904098510742\n",
            "mean_squared_errors 40: 47.202125549316406\n",
            "mean_squared_errors 41: 49.678646087646484\n",
            "mean_squared_errors 42: 46.07489776611328\n",
            "mean_squared_errors 43: 45.56820297241211\n",
            "mean_squared_errors 44: 49.93459701538086\n",
            "mean_squared_errors 45: 49.118228912353516\n",
            "mean_squared_errors 46: 60.152557373046875\n",
            "mean_squared_errors 47: 46.26445007324219\n",
            "mean_squared_errors 48: 45.92702102661133\n",
            "mean_squared_errors 49: 53.075836181640625\n",
            "mean_squared_errors 50: 50.02817153930664\n",
            "Mean: 62.99248307058773\n",
            "Standard Deviation: 43.55566011211207\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}