{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build a Regression Model in Keras(C).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBT_2iM0_jmj"
      },
      "source": [
        "# Start import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaxdftqR-hDp",
        "outputId": "ab5771a7-546d-432d-b338-f4f4948e44f6"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "concrete_data = pd.read_csv('concrete_data.csv')\r\n",
        "concrete_data.head()\r\n",
        "concrete_data.isnull().sum()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cement                0\n",
              "Blast Furnace Slag    0\n",
              "Fly Ash               0\n",
              "Water                 0\n",
              "Superplasticizer      0\n",
              "Coarse Aggregate      0\n",
              "Fine Aggregate        0\n",
              "Age                   0\n",
              "Strength              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo13on-3_uA-"
      },
      "source": [
        "# Build a baseline model\r\n",
        "Use the Keras library to build a neural network with the following:\r\n",
        "\r\n",
        "- One hidden layer of **10** nodes, and a **ReLU** activation function\r\n",
        "\r\n",
        "- Use the **adam** optimizer and the **mean squared erro**r  as the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jY5GCFw_zyH"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO6aAZ5kAEBI"
      },
      "source": [
        "def regression_model():\r\n",
        "    # create model with 10 nodes and a relu function\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(10, activation='relu', input_shape=(n_pred_cols ,)))\r\n",
        "    model.add(Dense(1))\r\n",
        "    \r\n",
        "    # compile model\r\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\r\n",
        "    return model\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZ82NwOAfJv"
      },
      "source": [
        "1. Randomly split the data into a training and test sets by holding **30%** of the data for testing. You can use the **train_test_splithelper function from Scikit-learn**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS9tjGpEAa3l"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md1LLHK7HN9Y"
      },
      "source": [
        "# normalized version of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQRLab5RA2Bx"
      },
      "source": [
        "# we need to use Strength column as our target to predict\r\n",
        "concrete_data_columns = concrete_data.columns\r\n",
        "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] \r\n",
        "target = concrete_data['Strength'] \r\n",
        "\r\n",
        "predictors_norm = (predictors - predictors.mean()) / predictors.std()\r\n",
        "predictors_norm.head()\r\n",
        "\r\n",
        "n_pred_cols = predictors.shape[1] # number of predictors\r\n",
        "n_pred_cols\r\n",
        "\r\n",
        "# split predictors data into training data and testing data (predictors is the column without Strength)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=40)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb7TdszuB-g3"
      },
      "source": [
        "2. Train the model on the training data using **100 epochs this time for training**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4XIuoNSBUNo",
        "outputId": "15a68c97-1b0b-41c2-b1fa-22b9f45b0b6d"
      },
      "source": [
        "model = regression_model()\r\n",
        "epochs = 100\r\n",
        "model.fit(X_train, y_train, epochs=epochs, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 1ms/step - loss: 25923.8296\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 6740.7846\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1736.3072\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1012.2057\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 970us/step - loss: 903.6139\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 874.7959\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 878.8300\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 791.0232\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 787.9307\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 797.6895\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 682.0160\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 664.7559\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 610.4120\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 683.2254\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 617.4697\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 556.2785\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 518.9685\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 587.1292\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 474.5179\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 507.9307\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 472.6956\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 492.3480\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 494.1303\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 454.4492\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 464.8661\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 406.7347\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 425.1223\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 401.1375\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 391.2372\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 381.4239\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 378.3325\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 394.2128\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 344.0681\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 346.4737\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 338.3313\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 346.4874\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 324.9530\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 329.2510\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 324.5852\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 321.3865\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 291.3167\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 309.8015\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 284.0619\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 297.6006\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 290.0977\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 286.1213\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 260.0285\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 265.6433\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 257.2701\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 254.2415\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 261.2008\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 240.4032\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 239.3272\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 224.6047\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 212.9125\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 229.0458\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 238.7928\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 218.7996\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 239.8575\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 197.6620\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 178.2709\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 197.8956\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 196.7582\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 191.4620\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 200.8510\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 189.1242\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 188.6655\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 188.1922\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 177.4286\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 166.5310\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 166.5671\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 161.4538\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 166.1657\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 168.9981\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 158.6524\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 154.2695\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 158.0742\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 147.1295\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 158.3959\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 153.6918\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 147.5108\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 151.2286\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 152.4441\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 145.7919\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 137.7759\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 133.6486\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 139.4949\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 125.5363\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 132.1125\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 129.2862\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 136.3105\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 121.6451\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 125.8571\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 115.9781\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 122.1437\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 115.1082\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 115.9512\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 113.3300\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 106.8105\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 120.7030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9e862ca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF0VY8ggDn36",
        "outputId": "6a6ef51d-da95-499c-8210-dbe6c23bd4f6"
      },
      "source": [
        "loss = model.evaluate(X_test, y_test)\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "loss"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 132.7438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132.74380493164062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wB_Q3J4Defr"
      },
      "source": [
        "3. Evaluate the model on the test data and compute the **mean squared error** between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6KBGICNDce2",
        "outputId": "2f37f4be-b58f-4496-e71e-2fdea529a304"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "mean_square_error = mean_squared_error(y_test, y_pred)\r\n",
        "mean = np.mean(mean_square_error)\r\n",
        "standard_deviation = np.std(mean_square_error)\r\n",
        "print(mean, standard_deviation)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "132.7438049832373 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D82Uc3R1EBxb"
      },
      "source": [
        "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\r\n",
        "\r\n",
        "100 epochs this time for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdk9h4mXEFQ4",
        "outputId": "40fe8508-0500-4b49-e804-2597f902d37f"
      },
      "source": [
        "repeat = 50\r\n",
        "epochs = 100\r\n",
        "mean_squared_errors = []\r\n",
        "for i in range(0, repeat):\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=i)\r\n",
        "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\r\n",
        "    MSE = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "    print(\"mean_squared_errors \"+str(i+1)+\": \"+str(MSE))\r\n",
        "    y_pred = model.predict(X_test)\r\n",
        "    mean_square_error = mean_squared_error(y_test, y_pred)\r\n",
        "    mean_squared_errors.append(mean_square_error)\r\n",
        "\r\n",
        "mean_squared_errors = np.array(mean_squared_errors)\r\n",
        "mean = np.mean(mean_squared_errors)\r\n",
        "standard_deviation = np.std(mean_squared_errors)\r\n",
        "\r\n",
        "print(\"Mean: \"+str(mean))\r\n",
        "print(\"Standard Deviation: \"+str(standard_deviation))\r\n",
        "print('\\n')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_squared_errors 1: 66.25251007080078\n",
            "mean_squared_errors 2: 69.00164031982422\n",
            "mean_squared_errors 3: 44.81114196777344\n",
            "mean_squared_errors 4: 49.16249084472656\n",
            "mean_squared_errors 5: 47.35177993774414\n",
            "mean_squared_errors 6: 50.308082580566406\n",
            "mean_squared_errors 7: 54.44255828857422\n",
            "mean_squared_errors 8: 41.9884033203125\n",
            "mean_squared_errors 9: 47.190452575683594\n",
            "mean_squared_errors 10: 49.10504150390625\n",
            "mean_squared_errors 11: 46.107322692871094\n",
            "mean_squared_errors 12: 43.051876068115234\n",
            "mean_squared_errors 13: 55.095481872558594\n",
            "mean_squared_errors 14: 48.82386016845703\n",
            "mean_squared_errors 15: 47.10914993286133\n",
            "mean_squared_errors 16: 41.15898513793945\n",
            "mean_squared_errors 17: 42.66764831542969\n",
            "mean_squared_errors 18: 42.9693717956543\n",
            "mean_squared_errors 19: 38.558101654052734\n",
            "mean_squared_errors 20: 44.08750915527344\n",
            "mean_squared_errors 21: 40.120731353759766\n",
            "mean_squared_errors 22: 45.96935272216797\n",
            "mean_squared_errors 23: 40.932403564453125\n",
            "mean_squared_errors 24: 44.577083587646484\n",
            "mean_squared_errors 25: 42.351707458496094\n",
            "mean_squared_errors 26: 45.7572135925293\n",
            "mean_squared_errors 27: 46.61017990112305\n",
            "mean_squared_errors 28: 41.25883102416992\n",
            "mean_squared_errors 29: 46.37081527709961\n",
            "mean_squared_errors 30: 43.62613296508789\n",
            "mean_squared_errors 31: 45.21263122558594\n",
            "mean_squared_errors 32: 40.00868606567383\n",
            "mean_squared_errors 33: 44.01099395751953\n",
            "mean_squared_errors 34: 42.01487731933594\n",
            "mean_squared_errors 35: 49.381431579589844\n",
            "mean_squared_errors 36: 48.179012298583984\n",
            "mean_squared_errors 37: 44.83922576904297\n",
            "mean_squared_errors 38: 47.198429107666016\n",
            "mean_squared_errors 39: 40.605899810791016\n",
            "mean_squared_errors 40: 40.36520767211914\n",
            "mean_squared_errors 41: 44.47087860107422\n",
            "mean_squared_errors 42: 39.8653678894043\n",
            "mean_squared_errors 43: 46.33012390136719\n",
            "mean_squared_errors 44: 44.77103042602539\n",
            "mean_squared_errors 45: 46.8160400390625\n",
            "mean_squared_errors 46: 42.863800048828125\n",
            "mean_squared_errors 47: 42.96092224121094\n",
            "mean_squared_errors 48: 42.68414306640625\n",
            "mean_squared_errors 49: 44.39509963989258\n",
            "mean_squared_errors 50: 48.56283187866211\n",
            "Mean: 45.8470896819392\n",
            "Standard Deviation: 5.6455261718558125\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}