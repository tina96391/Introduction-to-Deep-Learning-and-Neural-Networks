{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build a Regression Model in Keras(A).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBT_2iM0_jmj"
      },
      "source": [
        "# Start import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaxdftqR-hDp",
        "outputId": "83bf2435-7c7c-4892-fd66-72b39cf1b740"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "concrete_data = pd.read_csv('concrete_data.csv')\r\n",
        "concrete_data.head()\r\n",
        "concrete_data.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cement                0\n",
              "Blast Furnace Slag    0\n",
              "Fly Ash               0\n",
              "Water                 0\n",
              "Superplasticizer      0\n",
              "Coarse Aggregate      0\n",
              "Fine Aggregate        0\n",
              "Age                   0\n",
              "Strength              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo13on-3_uA-"
      },
      "source": [
        "# Build a baseline model\r\n",
        "Use the Keras library to build a neural network with the following:\r\n",
        "\r\n",
        "- One hidden layer of **10** nodes, and a **ReLU** activation function\r\n",
        "\r\n",
        "- Use the **adam** optimizer and the **mean squared erro**r  as the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jY5GCFw_zyH"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO6aAZ5kAEBI"
      },
      "source": [
        "def regression_model():\r\n",
        "    # create model with 10 nodes and a relu function\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(10, activation='relu', input_shape=(n_pred_cols ,)))\r\n",
        "    model.add(Dense(1))\r\n",
        "    \r\n",
        "    # compile model\r\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\r\n",
        "    return model\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZ82NwOAfJv"
      },
      "source": [
        "1. Randomly split the data into a training and test sets by holding **30%** of the data for testing. You can use the **train_test_splithelper function from Scikit-learn**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS9tjGpEAa3l"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQRLab5RA2Bx"
      },
      "source": [
        "# we need to use Strength column as our target to predict\r\n",
        "concrete_data_columns = concrete_data.columns\r\n",
        "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] \r\n",
        "target = concrete_data['Strength'] \r\n",
        "\r\n",
        "n_pred_cols = predictors.shape[1] # number of predictors\r\n",
        "n_pred_cols\r\n",
        "\r\n",
        "# split predictors data into training data and testing data (predictors is the column without Strength)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=40)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb7TdszuB-g3"
      },
      "source": [
        "2. Train the model on the training data using **50 epochs**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4XIuoNSBUNo",
        "outputId": "372072f0-95f1-4bc0-daa4-91eb04f56c47"
      },
      "source": [
        "model = regression_model()\r\n",
        "epochs = 50\r\n",
        "model.fit(X_train, y_train, epochs=epochs, verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 0s 839us/step - loss: 72830.3537\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 686us/step - loss: 19648.0456\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 5449.6308\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 5040.5197\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 957us/step - loss: 4111.5039\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 966us/step - loss: 3795.7530\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 968us/step - loss: 3321.6725\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 3033.2062\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 2653.7856\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 926us/step - loss: 2328.0679\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 2354.0818\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 2199.8996\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1990.9197\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1927.5227\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1662.1359\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 923us/step - loss: 1751.7449\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1740.8908\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1483.2876\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 964us/step - loss: 1556.5557\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 930us/step - loss: 1335.9796\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1380.8957\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1289.4584\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 990us/step - loss: 1209.8272\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1121.7698\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 775us/step - loss: 1114.7825\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1099.1408\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1056.4574\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 883.3579\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 944.4725\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 901.7915\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 871.8583\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 879.4955\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 835.1567\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 776.2373\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 752.8710\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 737.9722\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 677.0539\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 679.1894\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 671.2012\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 632.9350\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 603.8042\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 583.1720\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 644.7166\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 576.0574\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 535.6137\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 499.1260\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 546.7511\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 473.0240\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 482.1847\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 456.9601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5dfe7bb4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF0VY8ggDn36",
        "outputId": "5e445021-114d-4bbf-c9fa-22241a410692"
      },
      "source": [
        "loss = model.evaluate(X_test, y_test)\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "loss"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 426.4183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "426.41827392578125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wB_Q3J4Defr"
      },
      "source": [
        "3. Evaluate the model on the test data and compute the **mean squared error** between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6KBGICNDce2",
        "outputId": "b7af6f4c-c1ae-42d9-edb6-672aed7504df"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "mean_square_error = mean_squared_error(y_test, y_pred)\r\n",
        "mean = np.mean(mean_square_error)\r\n",
        "standard_deviation = np.std(mean_square_error)\r\n",
        "print(mean, standard_deviation)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "426.4183194393982 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D82Uc3R1EBxb"
      },
      "source": [
        "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdk9h4mXEFQ4",
        "outputId": "a44ae508-96ae-4920-c2de-1438b57d21be"
      },
      "source": [
        "repeat = 50\r\n",
        "epochs = 50\r\n",
        "mean_squared_errors = []\r\n",
        "for i in range(0, repeat):\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=i)\r\n",
        "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\r\n",
        "    MSE = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "    print(\"mean_squared_errors \"+str(i+1)+\": \"+str(MSE))\r\n",
        "    y_pred = model.predict(X_test)\r\n",
        "    mean_square_error = mean_squared_error(y_test, y_pred)\r\n",
        "    mean_squared_errors.append(mean_square_error)\r\n",
        "\r\n",
        "mean_squared_errors = np.array(mean_squared_errors)\r\n",
        "mean = np.mean(mean_squared_errors)\r\n",
        "standard_deviation = np.std(mean_squared_errors)\r\n",
        "\r\n",
        "print(\"Mean: \"+str(mean))\r\n",
        "print(\"Standard Deviation: \"+str(standard_deviation))\r\n",
        "print('\\n')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_squared_errors 1: 112.42803192138672\n",
            "mean_squared_errors 2: 127.3394546508789\n",
            "mean_squared_errors 3: 109.68777465820312\n",
            "mean_squared_errors 4: 130.0111083984375\n",
            "mean_squared_errors 5: 121.74201965332031\n",
            "mean_squared_errors 6: 96.76016235351562\n",
            "mean_squared_errors 7: 86.30403900146484\n",
            "mean_squared_errors 8: 55.16967010498047\n",
            "mean_squared_errors 9: 56.83612823486328\n",
            "mean_squared_errors 10: 54.67399215698242\n",
            "mean_squared_errors 11: 57.264625549316406\n",
            "mean_squared_errors 12: 48.350830078125\n",
            "mean_squared_errors 13: 57.07182312011719\n",
            "mean_squared_errors 14: 51.75748825073242\n",
            "mean_squared_errors 15: 53.8366584777832\n",
            "mean_squared_errors 16: 43.83550262451172\n",
            "mean_squared_errors 17: 46.9480094909668\n",
            "mean_squared_errors 18: 47.992794036865234\n",
            "mean_squared_errors 19: 43.443885803222656\n",
            "mean_squared_errors 20: 48.11425018310547\n",
            "mean_squared_errors 21: 41.6269645690918\n",
            "mean_squared_errors 22: 46.50067901611328\n",
            "mean_squared_errors 23: 43.56979751586914\n",
            "mean_squared_errors 24: 42.922916412353516\n",
            "mean_squared_errors 25: 47.6986083984375\n",
            "mean_squared_errors 26: 45.79423522949219\n",
            "mean_squared_errors 27: 48.63783264160156\n",
            "mean_squared_errors 28: 42.322078704833984\n",
            "mean_squared_errors 29: 52.54266357421875\n",
            "mean_squared_errors 30: 54.34764862060547\n",
            "mean_squared_errors 31: 63.453819274902344\n",
            "mean_squared_errors 32: 40.57575607299805\n",
            "mean_squared_errors 33: 48.14516830444336\n",
            "mean_squared_errors 34: 48.992862701416016\n",
            "mean_squared_errors 35: 44.41373825073242\n",
            "mean_squared_errors 36: 49.45818328857422\n",
            "mean_squared_errors 37: 48.78425598144531\n",
            "mean_squared_errors 38: 52.12100601196289\n",
            "mean_squared_errors 39: 54.14457702636719\n",
            "mean_squared_errors 40: 52.92661666870117\n",
            "mean_squared_errors 41: 55.26475143432617\n",
            "mean_squared_errors 42: 54.69113540649414\n",
            "mean_squared_errors 43: 45.34873962402344\n",
            "mean_squared_errors 44: 52.60921859741211\n",
            "mean_squared_errors 45: 52.068241119384766\n",
            "mean_squared_errors 46: 53.73396301269531\n",
            "mean_squared_errors 47: 46.819332122802734\n",
            "mean_squared_errors 48: 49.243526458740234\n",
            "mean_squared_errors 49: 48.824302673339844\n",
            "mean_squared_errors 50: 49.917572021484375\n",
            "Mean: 58.54136941720718\n",
            "Standard Deviation: 22.75615647045379\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}